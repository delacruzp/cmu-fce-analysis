{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from piazza_api import Piazza\n",
    "from functools import reduce\n",
    "from os import environ\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Piazza - API Crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_ids(course):\n",
    "    courses = []\n",
    "    \n",
    "    keys= [(\"cn\", \"course_cmu_id\"),\n",
    "    (\"n\", \"name\")]\n",
    "    \n",
    "    new_course = {}\n",
    "    terms = course.get('terms', {})\n",
    "    for key, new_key in keys:\n",
    "        new_course[new_key] = course.get(key)\n",
    "    \n",
    "    keys= [(\"cnt\", \"cnt\"),\n",
    "    (\"id\",\"course_piazza_id\"),\n",
    "    (\"prof\", \"prof\")]\n",
    "    \n",
    "    terms = course.get('terms', {})\n",
    "    for term in terms:\n",
    "        features = new_course.copy()\n",
    "        tmp = terms[term]\n",
    "        \n",
    "        features['term'] = term\n",
    "        \n",
    "        if 'id' not in tmp:\n",
    "            print('Skipped', features)\n",
    "            continue\n",
    "    \n",
    "        for key, new_key in keys:\n",
    "            features[new_key] = tmp.get(key)\n",
    "        \n",
    "        courses.append(features)\n",
    "\n",
    "    return courses\n",
    "\n",
    "def get_piazza_ids(filepath='./data/courses_ids.json'):\n",
    "    courses_ids = []\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        courses_ids = json.load(f)\n",
    "\n",
    "    extracted = map(_extract_ids, courses_ids)\n",
    "    extracted_flat = reduce(lambda a, b: a+b, extracted)\n",
    "    return extracted_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _extract_stats(stats):\n",
    "    features = {}\n",
    "\n",
    "    # Total\n",
    "    tmp = stats['total']\n",
    "    \n",
    "    keys= [(\"posts\", \"stats_posts\"),\n",
    "    (\"questions\", \"stats_questions\"),\n",
    "    (\"i_answers\", \"stats_i_answers\"),\n",
    "    (\"s_answers\", \"stats_s_answers\"),\n",
    "    (\"net_time\", \"stats_net_time\"),\n",
    "    (\"response_time\", \"stats_response_time\")]\n",
    "    \n",
    "    for key, new_key in keys:\n",
    "        features[new_key] = tmp.get(key)\n",
    "    \n",
    "    \n",
    "    keys = [(\"user_id\", \"top_user_%d_user_id\"),\n",
    "    (\"days\", \"top_user_%d_days\"),\n",
    "    (\"posts\", \"top_user_%d_posts\"),\n",
    "    (\"asks\", \"top_user_%d_asks\"),\n",
    "    (\"answers\", \"top_user_%d_answers\"),\n",
    "    (\"views\", \"top_user_%d_views\")]\n",
    "    \n",
    "    tmp = stats.get('top_users',[])\n",
    "    for i in range(min(3, len(tmp))):\n",
    "        top_user = tmp[i]\n",
    "        for key, new_key in keys:\n",
    "            features[new_key % i] = top_user.get(key)\n",
    "    \n",
    "    return features\n",
    "\n",
    "def get_piazza_stats(courses, \n",
    "                     out_filename=None, \n",
    "                     user=environ.get('PIAZZA_USER'),\n",
    "                     pwd=environ.get('PIAZZA_PWD')):\n",
    "    p = Piazza()\n",
    "    p.user_login(user,pwd)\n",
    "    \n",
    "    courses_data = []\n",
    "    total = len(courses)\n",
    "    for i, c_id in enumerate(courses):\n",
    "        print('%d/%d' % (i, total))\n",
    "        course = p.network(c_id)\n",
    "        stats = course.get_statistics()\n",
    "        features = _extract_stats(stats)\n",
    "        courses_data.append(features)\n",
    "        features['course_piazza_id'] = c_id\n",
    "    df = pd.DataFrame(courses_data) \n",
    "    if out_filename:\n",
    "        df.to_csv(out_filename, index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(in_filename='./data/courses_ids.json', out_filename='./data/piazza.csv'):\n",
    "    data = get_piazza_ids(filepath=in_filename)\n",
    "    df_details = pd.DataFrame(data)\n",
    "    df_stats = get_piazza_stats(df.course_piazza_id.values)\n",
    "    df = df_details.merge(df_stats, on='course_piazza_id')\n",
    "    df.to_csv(out_filename, index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FCE - Web Crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PENDING #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
